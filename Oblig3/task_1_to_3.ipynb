{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbedfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, gzip, json, re\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import encoder_client\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb57c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIALOGUE_FILE = \"en-comedy.txt.gz\"\n",
    "FIRST_NAMES = \"first_names.json\"\n",
    "MODEL_URI = \"https://home.nr.no/~plison/data/model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf8a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    \"\"\"A dual encoder model for a Retrieval chatbot\"\"\"\n",
    "    \n",
    "    def __init__(self, dialogue_data = DIALOGUE_FILE):\n",
    "        \"\"\"Initialises a chatbot based on a Dual Encoder architecture, with\n",
    "        utterances encoded using the pre-trained ConveRT model \n",
    "        (https://arxiv.org/abs/1911.03688).\"\"\"\n",
    "        \n",
    "        # Extracts the (context, response) pairs\n",
    "        self.pairs = self._extract_pairs(dialogue_data)\n",
    "        \n",
    "        # Loads the ConveRT utterance encoder\n",
    "        self.client = encoder_client.EncoderClient(\"https://home.nr.no/~plison/data/model.tar.gz\")\n",
    "        \n",
    "        # Compute the embeddings for the responses (takes some time to compute!)\n",
    "        responses = [response for _, response in self.pairs]\n",
    "        self.response_embeddings = self.client.encode_responses(responses)\n",
    "        \n",
    "    '''\n",
    "    def _cond_satisfied(self, column, names, outputs):\n",
    "        self.outputs = outputs\n",
    "        if not column.isupper():\n",
    "            if column[0] not in [\"♪\"]:\n",
    "                if not any(i in \"-¶,()[]:;\" for i in column):\n",
    "                    if \"...\" not in column:\n",
    "                        if column[0:3] not in [\"###\"]:\n",
    "                            if len(column.split()) < 10:\n",
    "                                if len(column.split()) > 1 and not any(i in names for i in self.outputs):\n",
    "                                    return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "        '''\n",
    "\n",
    "    def _extract_pairs(self, dialogue_data, max_nb_pairs=25000):\n",
    "        \"\"\"Given a file containing dialogue data, extracts a list of relevant\n",
    "        (context,response) pairs, where both the context and response are\n",
    "        strings. The 'context' is here simply the first utterance (such as a question),\n",
    "        and the 'response' the following utterance (such as an answer).\n",
    "\n",
    "        The (context, response) pairs should satisfy the following critera:\n",
    "        - The two strings should be consecutive, and part of the same movie/TV series\n",
    "        - Pairs in which one string contains commas, parentheses, brackets, colons, \n",
    "          semi-colons  or double quotes should be discarded.\n",
    "        - Pairs in which one string is entirely in uppercase should be discarded\n",
    "        - Pairs in which one string contains more than 10 words should be discarded\n",
    "        - Pairs in which one string contains a first name should be discarded \n",
    "          (see the json file FIRST_NAMES to detect those).\n",
    "        - Pairs in which the context string only contains one token should be discarded.\n",
    "\n",
    "        You are of course free to add additional critera to increase the quality of your\n",
    "        (context,response) pairs. You should stop the extract once you have reached \n",
    "        max_nb_pairs.\n",
    "\n",
    "        \"\"\"\n",
    "        #raise NotImplementedError()\n",
    "\n",
    "        self.outputs = []\n",
    "        nb_pair = 0\n",
    "\n",
    "        results = open(\"chatbot_output_file\", \"w\")\n",
    "        #'''\n",
    "        def _cond_satisfied(column):\n",
    "            if not any(c in \"-¶,()[]:;\"\"\" for c in column) and not column.isupper() and len(column.split()) < 10 and len(column.split()) > 1 and not any(c in names for c in column) and column[0] != '♪' and '...' not in column and column[0:3] != '###':\n",
    "                return True\n",
    "            \n",
    "            else:\n",
    "                return False\n",
    "        #'''\n",
    "\n",
    "        with open(FIRST_NAMES) as json_file:\n",
    "            names = json.load(json_file)\n",
    "\n",
    "        with open(dialogue_data, \"rb\") as gzip_file:\n",
    "            file = gzip.GzipFile(fileobj = gzip_file)\n",
    "            columns = file.readlines()\n",
    "\n",
    "            for context, response in zip(columns[0::2], columns[1::2]):\n",
    "                if nb_pair > max_nb_pairs:\n",
    "                    break\n",
    "\n",
    "                context  = context.decode(\"utf-8\").strip()\n",
    "                response = response.decode(\"utf-8\").strip()\n",
    "\n",
    "                #if self._cond_satisfied(context, names, self.outputs):\n",
    "                if _cond_satisfied(context):\n",
    "                    #if self._cond_satisfied(response, names, self.outputs):\n",
    "                    if _cond_satisfied(response):\n",
    "                        #print(\"hi\")\n",
    "                        self.outputs.append((context, response))\n",
    "                        results.write(f\"{(context, response)}\")\n",
    "                        results.write(\"\\n\")\n",
    "                        nb_pair = nb_pair + 1\n",
    "\n",
    "        results.close()\n",
    "        #print(f\"outputs: {self.outputs}\")\n",
    "        return self.outputs\n",
    "    \n",
    "    def get_response(self, user_utterance):\n",
    "        \"\"\"Extracts the context embedding for the user utterance, and then computes\n",
    "        the dot product of this embeddings with all the response embeddings (already\n",
    "        computed in self.response_embeddings). The response with the highest dot \n",
    "        product is then selected. \n",
    "        \n",
    "        To get the context embedding for the user utterance, simply use the method\n",
    "        client.encode_contexts(...).\n",
    "        \n",
    "        The method returns a string with the response of the chatbot.\"\"\"\n",
    "        \n",
    "        #raise NotImplementedError()\n",
    "\n",
    "        encoded_utterance = self.client.encode_contexts([user_utterance])\n",
    "\n",
    "        dot_product = []\n",
    "        for i in self.response_embeddings:\n",
    "            dot_product.append(np.dot(encoded_utterance, i))\n",
    "        ioptimal = dot_product.index(max(dot_product))\n",
    "\n",
    "        return self.pairs[ioptimal][1]\n",
    "        #return None\n",
    "    \n",
    "    def fine_tune(self):\n",
    "        \"\"\"Fine-tunes the dual encoder model by computing a transformation (linear \n",
    "        transformation + non-linear ReLU activation) of the response embeddings, \n",
    "        optimised on the (context, response) pairs extracted for the dataset. \n",
    "        The method updates the response embeddings with the transformed values\"\"\"\n",
    "        \n",
    "        # Extract the training data (with both positive and negative examples)\n",
    "        context_embeddings2, response_embeddings2, outputs = self._get_training_data()\n",
    "        \n",
    "        # Creates the two input layers (for the two embeddings)\n",
    "        input1 = tf.keras.layers.Input((context_embeddings2.shape[1],))\n",
    "        input2 = tf.keras.layers.Input((response_embeddings2.shape[1],))\n",
    "        \n",
    "        # Computes the linear transformation of the response embeddings\n",
    "        # (initialized with an identity matrix)\n",
    "        dense2 = tf.keras.layers.Dense(response_embeddings2.shape[1], \n",
    "                                       kernel_initializer=\"identity\", bias_initializer=\"zeros\")\n",
    "        \n",
    "        # Add dropout for regularisation\n",
    "        dropout = tf.keras.layers.Dropout(0.5)\n",
    "                \n",
    "        # Computes the dot product, and pass through a sigmoid to get a probability\n",
    "        dotproduct = tf.keras.layers.Dot(axes=1)\n",
    "        sigmoid = tf.keras.layers.Activation(tf.keras.activations.sigmoid)\n",
    "\n",
    "        # Connects together all layers\n",
    "        output_prob = sigmoid(dotproduct([dropout(input1), dense2(input2)]))\n",
    "        \n",
    "        # Creates a new model, specifying the inputs and output\n",
    "        model = tf.keras.Model([input1, input2], output_prob)\n",
    "        model.summary()   \n",
    "       \n",
    "        # Compile the model the \"Adam\" optimiser and a cross-entropy loss\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "        \n",
    "        # Train the model on 3 epochs\n",
    "        model.fit([context_embeddings2, response_embeddings2], outputs, \n",
    "                  batch_size=8,epochs=3, validation_split=0.1)\n",
    "        \n",
    "        # Once the model is trained, we simply transform the response embeddings using\n",
    "        # the transformation we have learned\n",
    "        embeddings_tensor = dense2(self.response_embeddings)\n",
    "        self.response_embeddings = tf.keras.backend.eval(embeddings_tensor)\n",
    "        \n",
    "        \n",
    "    def _get_training_data(self):\n",
    "        \"\"\"Constructs a dataset to fine-tune the dual encoder. The dataset should\n",
    "        contain both positive examples (that is, pairs of context and response embeddings\n",
    "        that do correspond to actual response pairs) and negative examples (pairs of context\n",
    "        and response embeddings that are selected at random and are not related).\n",
    "        \n",
    "        More precisely, the method should return 3 outputs:\n",
    "        - one matrix of shape (2*len(self.pairs), 512) with context embeddings from the pairs \n",
    "        - one matrix of shape (2*len(self.pairs), 512) with response embeddings from the pairs\n",
    "        - one array of shape 2*len(self.pairs) with binary values\n",
    "        \n",
    "        Half of the training examples should be positive (actual pair of embeddings) and half \n",
    "        should be negative (pair of embeddings selected at random), which is why the total length\n",
    "        of the training data is twice the number of (context, response) pairs. For positive examples,\n",
    "        the corresponding value in the output array should be 1, and 0 for negative examples.\n",
    "        \n",
    "        The response embeddings have already been computed (in self.response_embeddings) so you\n",
    "        don't need to compute them again. But you need to compute the context embeddings for your\n",
    "        pairs using the method client.encode_contexts(contexts). \n",
    "        \n",
    "        Note that the positive and negative examples should be shuffled (to avoid confusing the\n",
    "        machine learning model by first starting with only positive examples, then having on/uio/hume/student-u84/aleksda/Documents/aleksda_mandatory_3/ly \n",
    "        negative examples).\n",
    "        \"\"\"\n",
    "\n",
    "        #raise NotImplementedError()\n",
    "\n",
    "        context_embeddings  = self.client.encode_contexts([c for context, d in self.pairs])\n",
    "        response_embeddings = self.response_embeddings\n",
    "\n",
    "        temp_outputs = [1 for _ in range(len(context_embeddings))] + [0 for _ in range(len(context_embeddings))]\n",
    "\n",
    "        temp_context_train  = []\n",
    "        temp_response_train = []\n",
    "\n",
    "        for i, j in zip(range(len(context_embeddings)), range(len(response_embeddings))):\n",
    "            temp_context_train .append(response_embeddings[random.randint(0, len(context_embeddings) - 1)])\n",
    "            temp_response_train.append(context_embeddings[random.randint(0, len(response_embeddings) - 1)])\n",
    "\n",
    "        temp_context_train  = context_embeddings  + temp_context_train\n",
    "        temp_response_train = response_embeddings + temp_response_train\n",
    "\n",
    "        meshed_list = list(zip(temp_context_train, temp_response_train, temp_outputs))\n",
    "        meshed_list = random.shuffle(meshed_list)\n",
    "\n",
    "        context_train, response_train, outputs = zip(meshed_list[0], meshed_list[1], meshed_list[2])\n",
    "\n",
    "        return np.asarray(context_train),np.asarray(response_train), np.asarray(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e52de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = Chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f14fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_inputs = [\"Who are you?\", \"How old are you?\", \"Where are you?\", \"Are you stupid?\", \"Did you kill him?\"]\n",
    "for your_input in your_inputs:\n",
    "    print(f'You: {your_input}')\n",
    "    print(f'Chatbot: {cb.get_response(your_input)}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96445dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb.fine_tune()\n",
    "your_inputs = [\"Who are you?\", \"How old are you?\", \"Where are you?\", \"Are you stupid?\", \"Did you kill him?\"]\n",
    "for your_input in your_inputs:\n",
    "    print(f'You: {your_input}')\n",
    "    print(f'Chatbot: {cb.get_response(your_input)}')\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
